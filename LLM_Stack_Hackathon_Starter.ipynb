{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# LLM Stack Hackathon (June 3, 2023) Starter Kit"
      ],
      "metadata": {
        "id": "LkNZ6hp6K8l6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setup"
      ],
      "metadata": {
        "id": "rTCDcPB9LMjx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gdown pandas redis tqdm"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "id": "fRZYa2y3kcbk",
        "outputId": "ac63d6d3-8914-4993-b5bf-b06ff7008e47"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: gdown in /usr/local/lib/python3.10/dist-packages (4.6.6)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (1.5.3)\n",
            "Requirement already satisfied: redis in /usr/local/lib/python3.10/dist-packages (4.5.5)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (4.65.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from gdown) (3.12.0)\n",
            "Requirement already satisfied: requests[socks] in /usr/local/lib/python3.10/dist-packages (from gdown) (2.27.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from gdown) (1.16.0)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from gdown) (4.11.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2022.7.1)\n",
            "Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from pandas) (1.22.4)\n",
            "Requirement already satisfied: async-timeout>=4.0.2 in /usr/local/lib/python3.10/dist-packages (from redis) (4.0.2)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->gdown) (2.4.1)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (3.4)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (1.7.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Since we have some long lines, let's make sure output is line wrapped\n",
        "from IPython.display import HTML, display\n",
        "def set_css():\n",
        "  display(HTML('''\n",
        "  <style>\n",
        "    pre {\n",
        "        white-space: pre-wrap;\n",
        "    }\n",
        "  </style>\n",
        "  '''))\n",
        "get_ipython().events.register('pre_run_cell', set_css)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "iMTC5i-bMLwD",
        "outputId": "a2b8a031-73c6-4ed3-e260-c427a0222b53"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Download the data"
      ],
      "metadata": {
        "id": "qYS1Vk-xNRBj"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 642
        },
        "id": "Wxl__9HQGoML",
        "outputId": "84ba3fc8-5467-46d8-83f0-47dcab1c80bd"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Retrieving folder list\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing file 1QMNTLBTcgr2bZlwn072b2aabzAC8_EKO chats-embeddings-ada-002.csv\n",
            "Processing file 1eOta0PjQpn3spi8MsC2yLFBfKAeDMKDd chats.csv\n",
            "Processing file 1kdldUOEBYuxfKdLdRbSd0j4yh6nxEsEs LICENSE.txt\n",
            "Processing file 1soJjObg5XOSfY_Ie-s0B2akUibz2Hg9M messages-embeddings-ada-002.csv\n",
            "Processing file 1i-Rqg9bGlTNZ-fm2Ui37qHvWYlIv9FrJ messages.csv\n",
            "Building directory structure completed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Retrieving folder list completed\n",
            "Building directory structure\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1QMNTLBTcgr2bZlwn072b2aabzAC8_EKO\n",
            "To: /content/LLM Stack Hackathon/chats-embeddings-ada-002.csv\n",
            "100%|██████████| 334M/334M [00:01<00:00, 190MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1eOta0PjQpn3spi8MsC2yLFBfKAeDMKDd\n",
            "To: /content/LLM Stack Hackathon/chats.csv\n",
            "100%|██████████| 15.1M/15.1M [00:00<00:00, 24.5MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1kdldUOEBYuxfKdLdRbSd0j4yh6nxEsEs\n",
            "To: /content/LLM Stack Hackathon/LICENSE.txt\n",
            "100%|██████████| 166/166 [00:00<00:00, 441kB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1soJjObg5XOSfY_Ie-s0B2akUibz2Hg9M\n",
            "To: /content/LLM Stack Hackathon/messages-embeddings-ada-002.csv\n",
            "100%|██████████| 2.16G/2.16G [00:26<00:00, 81.7MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1i-Rqg9bGlTNZ-fm2Ui37qHvWYlIv9FrJ\n",
            "To: /content/LLM Stack Hackathon/messages.csv\n",
            "100%|██████████| 26.0M/26.0M [00:00<00:00, 162MB/s]\n",
            "Download completed\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['/content/LLM Stack Hackathon/chats-embeddings-ada-002.csv',\n",
              " '/content/LLM Stack Hackathon/chats.csv',\n",
              " '/content/LLM Stack Hackathon/LICENSE.txt',\n",
              " '/content/LLM Stack Hackathon/messages-embeddings-ada-002.csv',\n",
              " '/content/LLM Stack Hackathon/messages.csv']"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "import gdown\n",
        "gdown.download_folder(\"https://drive.google.com/drive/folders/1FCuU2j8yI7hXsZL8Ls_fgJwUn7-Dx_VV?usp=sharing\", quiet=False)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd"
      ],
      "metadata": {
        "id": "yL5itBTIKmzq",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "983cebb9-f9a1-46c0-8e76-c34d53133384"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Raw Messages & Embeddings"
      ],
      "metadata": {
        "id": "ff4PODEINaXH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Raw messages\n",
        "messages_df = pd.read_csv(\"./LLM Stack Hackathon/messages.csv\")\n",
        "messages_df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "Gb3WVLtRJpsN",
        "outputId": "f1cfe61a-b8c3-43a0-cf18-9e868b1da0e3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "  __Source      User_ID              Channel_Name  \\\n",
              "0  threads  U01T78HPG3H           computer-vision   \n",
              "1  threads  U01T78HPG3H           computer-vision   \n",
              "2  threads  U04QRD69H8Q           computer-vision   \n",
              "3  threads  U01J0NVNE1G  mlops-questions-answered   \n",
              "4  threads  U01J0NVNE1G  mlops-questions-answered   \n",
              "\n",
              "                Message_Timestamp                 Thread_Timstamp  \\\n",
              "0  2023-05-18 11:36:44.001949 UTC  2023-05-18 11:30:13.159979 UTC   \n",
              "1  2023-05-18 11:30:13.159979 UTC  2023-05-18 11:30:13.159979 UTC   \n",
              "2  2023-05-18 10:56:33.313369 UTC  2023-05-17 12:35:14.522419 UTC   \n",
              "3  2023-05-18 05:21:04.346819 UTC  2023-05-18 01:08:57.948139 UTC   \n",
              "4  2023-05-18 05:19:51.718379 UTC  2023-05-18 01:08:57.948139 UTC   \n",
              "\n",
              "    Channel_ID                                             __Text  \n",
              "0  C026ED0PZEZ  Both <https://roboflow.github.io/supervision/q...  \n",
              "1  C026ED0PZEZ  Would love a package for suggesting and then i...  \n",
              "2  C026ED0PZEZ  <@U056Q4V4FFC> how about this dataset (for the...  \n",
              "3  C015J2Y9RLM  I always oppose the counterargument, why do yo...  \n",
              "4  C015J2Y9RLM  I find MLflow more convenient to use. Here are...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-42b40d13-83fc-437f-b71a-796b45cd4989\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>__Source</th>\n",
              "      <th>User_ID</th>\n",
              "      <th>Channel_Name</th>\n",
              "      <th>Message_Timestamp</th>\n",
              "      <th>Thread_Timstamp</th>\n",
              "      <th>Channel_ID</th>\n",
              "      <th>__Text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>threads</td>\n",
              "      <td>U01T78HPG3H</td>\n",
              "      <td>computer-vision</td>\n",
              "      <td>2023-05-18 11:36:44.001949 UTC</td>\n",
              "      <td>2023-05-18 11:30:13.159979 UTC</td>\n",
              "      <td>C026ED0PZEZ</td>\n",
              "      <td>Both &lt;https://roboflow.github.io/supervision/q...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>threads</td>\n",
              "      <td>U01T78HPG3H</td>\n",
              "      <td>computer-vision</td>\n",
              "      <td>2023-05-18 11:30:13.159979 UTC</td>\n",
              "      <td>2023-05-18 11:30:13.159979 UTC</td>\n",
              "      <td>C026ED0PZEZ</td>\n",
              "      <td>Would love a package for suggesting and then i...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>threads</td>\n",
              "      <td>U04QRD69H8Q</td>\n",
              "      <td>computer-vision</td>\n",
              "      <td>2023-05-18 10:56:33.313369 UTC</td>\n",
              "      <td>2023-05-17 12:35:14.522419 UTC</td>\n",
              "      <td>C026ED0PZEZ</td>\n",
              "      <td>&lt;@U056Q4V4FFC&gt; how about this dataset (for the...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>threads</td>\n",
              "      <td>U01J0NVNE1G</td>\n",
              "      <td>mlops-questions-answered</td>\n",
              "      <td>2023-05-18 05:21:04.346819 UTC</td>\n",
              "      <td>2023-05-18 01:08:57.948139 UTC</td>\n",
              "      <td>C015J2Y9RLM</td>\n",
              "      <td>I always oppose the counterargument, why do yo...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>threads</td>\n",
              "      <td>U01J0NVNE1G</td>\n",
              "      <td>mlops-questions-answered</td>\n",
              "      <td>2023-05-18 05:19:51.718379 UTC</td>\n",
              "      <td>2023-05-18 01:08:57.948139 UTC</td>\n",
              "      <td>C015J2Y9RLM</td>\n",
              "      <td>I find MLflow more convenient to use. Here are...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-42b40d13-83fc-437f-b71a-796b45cd4989')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-42b40d13-83fc-437f-b71a-796b45cd4989 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-42b40d13-83fc-437f-b71a-796b45cd4989');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get all data for specific channel\n",
        "df_mlops_questions_answered = messages_df[messages_df[\"Channel_Name\"]==\"mlops-questions-answered\"]\n",
        "df_mlops_questions_answered.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "t2DI96m7OOjK",
        "outputId": "18156c77-12f3-40f0-a03a-677acd5bb672"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "    __Source      User_ID              Channel_Name  \\\n",
              "3    threads  U01J0NVNE1G  mlops-questions-answered   \n",
              "4    threads  U01J0NVNE1G  mlops-questions-answered   \n",
              "5    threads  U01CRVDS4NA  mlops-questions-answered   \n",
              "7   messages  U01VCA57PD0  mlops-questions-answered   \n",
              "21  messages  U015BH45ZK6  mlops-questions-answered   \n",
              "\n",
              "                 Message_Timestamp                 Thread_Timstamp  \\\n",
              "3   2023-05-18 05:21:04.346819 UTC  2023-05-18 01:08:57.948139 UTC   \n",
              "4   2023-05-18 05:19:51.718379 UTC  2023-05-18 01:08:57.948139 UTC   \n",
              "5   2023-05-18 05:14:52.514189 UTC  2023-05-16 23:22:04.332479 UTC   \n",
              "7   2023-05-18 01:08:57.948139 UTC  2023-05-18 01:08:57.948139 UTC   \n",
              "21  2023-05-17 14:56:59.775629 UTC  2023-05-17 14:56:59.775629 UTC   \n",
              "\n",
              "     Channel_ID                                             __Text  \n",
              "3   C015J2Y9RLM  I always oppose the counterargument, why do yo...  \n",
              "4   C015J2Y9RLM  I find MLflow more convenient to use. Here are...  \n",
              "5   C015J2Y9RLM  I just built some demos with it. The developer...  \n",
              "7   C015J2Y9RLM  These days I'm feeling very tempted to roll my...  \n",
              "21  C015J2Y9RLM  I ran into a problem downloading files from Az...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-ea8211ee-c496-48bc-ac11-9ede91246aae\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>__Source</th>\n",
              "      <th>User_ID</th>\n",
              "      <th>Channel_Name</th>\n",
              "      <th>Message_Timestamp</th>\n",
              "      <th>Thread_Timstamp</th>\n",
              "      <th>Channel_ID</th>\n",
              "      <th>__Text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>threads</td>\n",
              "      <td>U01J0NVNE1G</td>\n",
              "      <td>mlops-questions-answered</td>\n",
              "      <td>2023-05-18 05:21:04.346819 UTC</td>\n",
              "      <td>2023-05-18 01:08:57.948139 UTC</td>\n",
              "      <td>C015J2Y9RLM</td>\n",
              "      <td>I always oppose the counterargument, why do yo...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>threads</td>\n",
              "      <td>U01J0NVNE1G</td>\n",
              "      <td>mlops-questions-answered</td>\n",
              "      <td>2023-05-18 05:19:51.718379 UTC</td>\n",
              "      <td>2023-05-18 01:08:57.948139 UTC</td>\n",
              "      <td>C015J2Y9RLM</td>\n",
              "      <td>I find MLflow more convenient to use. Here are...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>threads</td>\n",
              "      <td>U01CRVDS4NA</td>\n",
              "      <td>mlops-questions-answered</td>\n",
              "      <td>2023-05-18 05:14:52.514189 UTC</td>\n",
              "      <td>2023-05-16 23:22:04.332479 UTC</td>\n",
              "      <td>C015J2Y9RLM</td>\n",
              "      <td>I just built some demos with it. The developer...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>messages</td>\n",
              "      <td>U01VCA57PD0</td>\n",
              "      <td>mlops-questions-answered</td>\n",
              "      <td>2023-05-18 01:08:57.948139 UTC</td>\n",
              "      <td>2023-05-18 01:08:57.948139 UTC</td>\n",
              "      <td>C015J2Y9RLM</td>\n",
              "      <td>These days I'm feeling very tempted to roll my...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>messages</td>\n",
              "      <td>U015BH45ZK6</td>\n",
              "      <td>mlops-questions-answered</td>\n",
              "      <td>2023-05-17 14:56:59.775629 UTC</td>\n",
              "      <td>2023-05-17 14:56:59.775629 UTC</td>\n",
              "      <td>C015J2Y9RLM</td>\n",
              "      <td>I ran into a problem downloading files from Az...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ea8211ee-c496-48bc-ac11-9ede91246aae')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-ea8211ee-c496-48bc-ac11-9ede91246aae button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-ea8211ee-c496-48bc-ac11-9ede91246aae');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the count of conversations\n",
        "print(f\"Number of conversations: {len(df_mlops_questions_answered.groupby(['Thread_Timstamp']))}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "NhceGvxtOUff",
        "outputId": "c87dade7-1705-4146-f0ed-38fa41bbaa4e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of conversations: 2086\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Iterate through conversations\n",
        "from IPython.display import HTML, display\n",
        "\n",
        "NUM_CONVERSATIONS_TO_PRINT=5\n",
        "current_conversation=0\n",
        "for (channel_name, thread_id), conv in df_mlops_questions_answered.groupby(['Channel_Name', 'Thread_Timstamp']):\n",
        "  html = f\"<h2>Channel: {channel_name} / conversation {thread_id} </h2><hr/>\\n<table>\\n\"\n",
        "  for index, row in conv.iterrows():\n",
        "    html+= f'<tr><td>{row[\"User_ID\"]}</td><td>{row[\"__Text\"]}</td></tr>'\n",
        "  html += f\"</table>\\n<hr/><br/>\"\n",
        "  display(HTML(html))\n",
        "  current_conversation+=1\n",
        "  if current_conversation>=NUM_CONVERSATIONS_TO_PRINT:\n",
        "    break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "tBg-2ZBvOZ8p",
        "outputId": "d1754640-0378-4998-ea4a-f1f9da8f301a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<h2>Channel: mlops-questions-answered / conversation 2020-06-19 20:44:41.0065 UTC </h2><hr/>\n",
              "<table>\n",
              "<tr><td>U011NTHUKEF</td><td>We use a lot of TPOT library. The main advantage is that it does hyperparameter tunning and also deals with preprocessing steps as well... downside is that it works mostly with scikit-learn algorithms. But there is a small hack you can do to make it work with many algorithms... make a new algo class that inherits both from sklearn BaseEstimators and your algo (Catboost, for example, or Pygams)</td></tr><tr><td>U015CHWG25B</td><td>Aha, I’ve heard that it’s really good!</td></tr><tr><td>U0150LZ578X</td><td>For anyone already using other Kubeflow components, Katib is relatively easy to work with <https://github.com/kubeflow/katib>\n",
              "\n",
              "It parallelizes trials across k8s pods and provides a web UI to visualize the hyperparameter space for each training history!</td></tr><tr><td>U015CHWG25B</td><td><@U013CL3GTB3> Thank you! Looks like this is an entire ML platform rather than just a hyperparameter tuning tool :thinking_face: </td></tr><tr><td>U013CL3GTB3</td><td>Polyaxon is another good one! <https://medium.com/polyaxon/polyaxon-0-0-2-23964df6ef7e|https://medium.com/polyaxon/polyaxon-0-0-2-23964df6ef7e></td></tr><tr><td>U015CHWG25B</td><td>At some point we reviewed about 15 hyperparameter tuning tools in order to choose one that answers our needs. We stopped at NNI from Microsoft (<https://github.com/microsoft/Nni|https://github.com/microsoft/Nni>). This tool is designed to run hyperparameter tuning in several parallel jobs. Unlike many other tools, it supports a lot of different algorithms of hyperparameter tuning. It has a decent UI. Plus, it's OSS from Microsoft :) Do you know other tools which answer our criteria?</td></tr><tr><td>U015CHWG25B</td><td>I want to run hyperparameter tuning on several machines in parallel and track the process in Web UI. What is the best tool for that?</td></tr></table>\n",
              "<hr/><br/>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<h2>Channel: mlops-questions-answered / conversation 2020-06-19 20:45:07.0067 UTC </h2><hr/>\n",
              "<table>\n",
              "<tr><td>U011NTHUKEF</td><td>AirFlow is a great tool. We use it a lot. When we work on a AWS environment, we use AWS stepfunctions which has its own Data Science SDK. Works like a charm!</td></tr><tr><td>U015CHWG25B</td><td>This is a clear usecase for pipeline tools. There are plenty of them out there, providing various features and UI capabilities. Currently, for our projects we use AirFlow. Which pipeline tools do you prefer and why?</td></tr><tr><td>U015CHWG25B</td><td>OK, I have a model of decent quality. Now I want to automate daily collecting data, retraining the model, and redeployment. How do I do that?</td></tr></table>\n",
              "<hr/><br/>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<h2>Channel: mlops-questions-answered / conversation 2020-06-24 00:53:14.0183 UTC </h2><hr/>\n",
              "<table>\n",
              "<tr><td>U015CHWG25B</td><td>Sure, thank you! :pray:</td></tr><tr><td>U016A3RAL5N</td><td><@U015CHWG25B> thanks for including us in your list. If you need any support lest us know</td></tr></table>\n",
              "<hr/><br/>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<h2>Channel: mlops-questions-answered / conversation 2020-06-24 17:51:24.026 UTC </h2><hr/>\n",
              "<table>\n",
              "<tr><td>UV92GMLF4</td><td><@U014Z58NT25> Sorry for the late reply:\n",
              "\n",
              "1. It's determined by marketing. The thing that we do it's just to highlight who is in the border. \n",
              "2. We used only numericals in that time, but OHE work fine also. \n",
              "3. At the that time, we didn't used any specific tool. I think today it's doable to do in matplotlib if you transform in 2D array those records from the cluster. </td></tr><tr><td>U012YQULW4X</td><td>you seem to treat it as a technical problem (automate the encoding). This issue points you to a potentially significant change in the input data so you want to notice and manually investigate. For detection, you can check tools for data monitoring like <https://github.com/great-expectations/great_expectations> or tensorflow data monitoring. They should be able to check feature cardinality (number of segments).\n",
              "\n",
              "Segments: Do I understand you correctly that the marketing team changed the logic for the segment variable e.g. an prior \"A\" customer might now be a \"B\" customer?\n",
              "Case A: Feature is not important. Fix encoding bug and move on.\n",
              "Case B: The feature is important but not a lot of customers migrated their segment. Fix encoding bug and move on.\n",
              "Case C:  Feature is important and the logic is very different or many people migrated. This is possibly a breaking change in the data and you need a migration plan (discard training data with old logic, not use the feature for the migration duration etc):\n",
              "\n",
              "you mention: \"everytime this happens\". That should not happen regularly. If it does, you have to stop using the feature/understand better what they do and what it means. Constantly changing data definitions make the feature dangerous to use.</td></tr><tr><td>UP3T8K9M5</td><td>maybe <@U012YQULW4X> can also help as she has some experience with monitoring and will be talking to us about it during this week’s meetup</td></tr><tr><td>U014Z58NT25</td><td>And thanks for the answers guys! It really helps even just to talk about the problem</td></tr><tr><td>U014Z58NT25</td><td><@UV92GMLF4> the clusters were determined by the marketing in the sense of \"good cluster/bad cluster\" or they even gave you a centroid for that? Could you use anything but numericals for KMeans? Essentially I know you can't, for you have to deal with distances. But someone has once told me you can sometimes work with binary/ordinal using KMeans as well.\n",
              "Also, did you have anything (besides your own code and CLI) for monitoring those jumpers? Any specific tools or dashboards</td></tr><tr><td>U014Z58NT25</td><td><@U013CL3GTB3> What happens is that as of now I have, say, 5 customer segments. On the data that I extract tomorrow, I might have 6, cause this customer segmentation is something still being created by the business, and I won't know it in advance.\n",
              "\n",
              "I can extract some meaning from these classes and put them into an ascending order (of integers, for example). And yes, I wanna use them for my recsys at the end of the day.\n",
              "\n",
              "EDIT: typo</td></tr><tr><td>UP3T8K9M5</td><td><@U0156CADGJG> might have something to say about this too</td></tr><tr><td>UV92GMLF4</td><td>Those guys I removed from the clusters and put them in another cluster (determined by marketing).\n",
              "\n",
              "Was totally primitive and I was using the KMeans, but the general idea it's that.</td></tr><tr><td>UV92GMLF4</td><td>In pink I got the \"jumpers\".</td></tr><tr><td>UV92GMLF4</td><td>Those are the clusters (just for simplification)</td></tr><tr><td>UV92GMLF4</td><td>Hey Murilo! What's up!\n",
              "\n",
              "I worked with that in a long time ago (2015) so maybe my answer it's outdated.\n",
              "\n",
              "In my case, I had fixed clusters (due to the fact those clusters where determined by Marketing); so the only thing that I monitor in this case was 1) the Centroid (to check if there's some changes in the centroid (drift) and 2) in the instances that I call \"jumpers\", i.e. records that shifted to some point of clusters boarders.\n",
              "\n",
              "Like this.</td></tr><tr><td>U013CL3GTB3</td><td>• Are these segment features known in advance? Or are they being generated on the fly? Are they different every time? Is it possible to know the values in advance? \n",
              "• can you clarify what you mean by “encoding” ? Are you given a string and want to turn it into a int or float? I’m assuming you use it as a feature for the recommender system.</td></tr><tr><td>U014Z58NT25</td><td>Hey guys! In the matter of concept drifting, I have a clustering algorithm (that is mainly a recommendation system for our business) that takes into account a categorical variable called \"Customer Segment\", that is translated in an ordinal fashion - i.e. \"better\" clients go to a higher number. Due to this new scenario we're going through, some new segments showed up and everytime this happens I have to manually determine how to encode them. Is there a way to automate this? Or even tools to identify when it happens would already help me out a lot. Thanks!</td></tr></table>\n",
              "<hr/><br/>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<h2>Channel: mlops-questions-answered / conversation 2020-06-27 19:23:54.0496 UTC </h2><hr/>\n",
              "<table>\n",
              "<tr><td>U016FCTSDGS</td><td>Few answers from our experience:\n",
              "1. We keep Airflow stack separate from DAG Projects. We also have a single repo per DAG project that gets auto-named and deployed in such a way that Airflow picks it up to sync in the DAG folder.  We also have a DAG that runs frequently to scan and ingest the new DAG(s) from the DAG Projects.\n",
              "2. If the question is long running tasks we spin up AWS Batch or AWS EMR depending on the need. If the question is how to interject DAG updates if a long running task is executing then no solution here other than on the next run the task(s)/DAG will get updated.\n",
              "3. Did not know about the *`PythonVirtualenvOperator`*  or would have used it. We just installed custom python packages to a temp directory and added to Python path, then deleted the folder in the last task for cleanup.\n",
              "4. Haven't used Docker Operator.\n",
              "5. Let me know if you find one!</td></tr><tr><td>U015CHWG25B</td><td>I can’t answer all your questions one by one, but I can share the basics of our approach.\n",
              "• Regarding deployment: We use Git to deploy DAGs. In our case, we have a dedicated repo for DAGs, and AirFlow installation polls this repo every minute and redeploys DAGs if necessary. Thus your DAGs are separated from your Airflow service.\n",
              "• Regarding tasks: We chose to make our own operator (as we have an ML platform with some specificity) based on DockerOperator. Containerisation of each step gives you way more freedom, especially in complex pipelines when you may need even different versions of CUDA for different steps. \n",
              "</td></tr><tr><td>U013K7876BF</td><td>thanks for the responses <@U013CL3GTB3> and <@U0158N59C8H>\n",
              "Flux sounds great, but I’m going need to work with a push model (we have some constraints in our system -  we can’t access the repo from the cloud)\n",
              "If i’m pushing the scheduler just to kick off a `KubernetesPodOperator`, Airflow feels very similar to Argo.</td></tr><tr><td>UP3T8K9M5</td><td>hmmm yeah i also would like to know this.</td></tr><tr><td>U0158N59C8H</td><td>Nope. I mean I use argo quite a bit via kubeflow pipelines. I used airflow too. Just wanting to get more opinions on the diff solutions.\n",
              "\n",
              "Esp Argo vs Tekton. As they are very closely related.</td></tr><tr><td>UP3T8K9M5</td><td>I also remember <@U0158N59C8H> was asking about Argo a while back. Were you able to get any info that could help us? </td></tr><tr><td>U013CL3GTB3</td><td>1. I would launch the task in a pod using the kubernetesPodOperator. And for pushing your dags, use gitops! You can point your airflow deployment to a git branch. This requires flux and some other stuff to be in place.\n",
              "2. Not sure what you mean by long running airflow service? Are you saying how to update a task independent of airflow itself like the web server or scheduler?  - if you're launching your tasks in pods you leave the execution logic to the docker container running in the pod and the orchestration logic to airflow. I would also recommend using the KubernetesExecutor alongside the KubernetesPodOperator. \n",
              "3. The kubernetesPodOperator also solves this problem as you have complete control over the runtime environment, resources, etc - the container has everything it needs to run the code\n",
              "4. Haven’t used the docker operator but It sounds like it’s more general than just python code. And will allow you to containerize your code which deals with the dependency issue.\n",
              "5. My company BenevolentAI Is about to publish an article about some lessons we learned using airflow so I’ll post it to the community when it’s out.\n",
              "Also me and <@UP3T8K9M5> are planning on doing a coffee session on pipelines - and airflow will be one of them. You mentioned Argo, that’s also another good option as it’s native to kubernetes which is nice and also has other benefits.</td></tr><tr><td>U013K7876BF</td><td>Hey everyone\n",
              "We’re looking for productionize some data engineering pipelines but we really want this run on Airflow and have a proper CI/CD pipeline.\n",
              "I have a couple of questions, and I’m hoping some of you may have experience and knowledge about these topics.\n",
              "1. Would you deploy the Airflow task along with the Airflow service itself? How else would you push your DAGs from source control into the dags folder of Airflow?\n",
              "2. Is there an elegant way to update the tasks separately from a long running Airflow service?\n",
              "3. Given that not all tasks have the same python dependencies, how does dependency management work? Do you install all of the dependencies with Airflow itself, or do you use `PythonVirtualenvOperator` to create a virtual env for each step in the dag?\n",
              "4. How difficult is monitoring and debugging when using `airflow.operators.docker_operator`? we can package each step in our data engineering pipeline in an .py file with a `main` and create a container. Does it have clear benefits over the `PythonVirtualenvOperator?`\n",
              "5. If there are good resource on airflow deployment strategies, I’d love to read more. I was looking at Argo <https://github.com/argoproj/argo> and if help have experience with Argo vs Airflow I’d love to hear that too.\n",
              "Thanks!</td></tr></table>\n",
              "<hr/><br/>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Embeddings data for each message (rahul is generating this rn.) \n",
        "message_embeddings_df = pd.read_csv(\"./LLM Stack Hackathon/messages-embeddings-ada-002.csv\")\n",
        "message_embeddings_df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "8tKT42ffOZ57",
        "outputId": "8e1a87fd-4d60-41da-cd4b-6abf1adcd1df"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Unnamed: 0                    message_id  \\\n",
              "0           0  2020-03-17 22:52:45.0174 UTC   \n",
              "1           1  2020-03-17 22:58:47.0175 UTC   \n",
              "2           2  2020-03-18 06:39:01.0184 UTC   \n",
              "3           3  2020-03-18 06:40:19.0195 UTC   \n",
              "4           4  2020-03-18 06:40:58.0198 UTC   \n",
              "\n",
              "                                           embedding  \n",
              "0  [-0.043248970061540604, -0.007734753657132387,...  \n",
              "1  [-0.03162849321961403, 0.0018300998490303755, ...  \n",
              "2  [-0.021394122391939163, -0.013377929106354713,...  \n",
              "3  [0.014829986728727818, -0.01779334992170334, 0...  \n",
              "4  [0.013494313694536686, -0.009085348807275295, ...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-2d088f05-3fd5-4e84-af3c-e82bf842ceeb\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>message_id</th>\n",
              "      <th>embedding</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>2020-03-17 22:52:45.0174 UTC</td>\n",
              "      <td>[-0.043248970061540604, -0.007734753657132387,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>2020-03-17 22:58:47.0175 UTC</td>\n",
              "      <td>[-0.03162849321961403, 0.0018300998490303755, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>2020-03-18 06:39:01.0184 UTC</td>\n",
              "      <td>[-0.021394122391939163, -0.013377929106354713,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>2020-03-18 06:40:19.0195 UTC</td>\n",
              "      <td>[0.014829986728727818, -0.01779334992170334, 0...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>2020-03-18 06:40:58.0198 UTC</td>\n",
              "      <td>[0.013494313694536686, -0.009085348807275295, ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2d088f05-3fd5-4e84-af3c-e82bf842ceeb')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-2d088f05-3fd5-4e84-af3c-e82bf842ceeb button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-2d088f05-3fd5-4e84-af3c-e82bf842ceeb');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Conversations & Embeddings"
      ],
      "metadata": {
        "id": "K1W_efjwNiut"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Each conversation grouped into a single thread_id\n",
        "chats_df = pd.read_csv(\"./LLM Stack Hackathon/chats.csv\")\n",
        "chats_df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "xTGDU-5RKwLz",
        "outputId": "173f13f0-e747-441b-bade-25338f69f4fc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Unnamed: 0 channel_name                       thread_id  \\\n",
              "0           0       africa  2022-03-22 19:42:06.219769 UTC   \n",
              "1           1       africa  2022-03-24 08:14:33.140029 UTC   \n",
              "2           2       africa  2022-03-28 11:57:42.840049 UTC   \n",
              "3           3       africa  2022-04-12 14:36:00.144498 UTC   \n",
              "4           4       africa  2022-04-19 10:24:57.455849 UTC   \n",
              "\n",
              "                                           chat_text  \n",
              "0  U024WRAA0D9: Hello fellow MLOpsers in Africa :...  \n",
              "1  U024WRAA0D9: What should our next steps be (fo...  \n",
              "2  U024WRAA0D9: What’s everyone’s timezone?U024WR...  \n",
              "3  U03142DQP6Z: Please can we make it later in th...  \n",
              "4  U024WRAA0D9: Hello <#C037GTG932B|africa>, I on...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-7bdcdc75-79a8-4c03-bb23-f70752f66ff2\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>channel_name</th>\n",
              "      <th>thread_id</th>\n",
              "      <th>chat_text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>africa</td>\n",
              "      <td>2022-03-22 19:42:06.219769 UTC</td>\n",
              "      <td>U024WRAA0D9: Hello fellow MLOpsers in Africa :...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>africa</td>\n",
              "      <td>2022-03-24 08:14:33.140029 UTC</td>\n",
              "      <td>U024WRAA0D9: What should our next steps be (fo...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>africa</td>\n",
              "      <td>2022-03-28 11:57:42.840049 UTC</td>\n",
              "      <td>U024WRAA0D9: What’s everyone’s timezone?U024WR...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>africa</td>\n",
              "      <td>2022-04-12 14:36:00.144498 UTC</td>\n",
              "      <td>U03142DQP6Z: Please can we make it later in th...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>africa</td>\n",
              "      <td>2022-04-19 10:24:57.455849 UTC</td>\n",
              "      <td>U024WRAA0D9: Hello &lt;#C037GTG932B|africa&gt;, I on...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7bdcdc75-79a8-4c03-bb23-f70752f66ff2')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-7bdcdc75-79a8-4c03-bb23-f70752f66ff2 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-7bdcdc75-79a8-4c03-bb23-f70752f66ff2');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# The embedding for each conversation with its thread_id (Note: not all embeddings were generated for the chat text)\n",
        "embeddings_df = pd.read_csv(\"./LLM Stack Hackathon/chats-embeddings-ada-002.csv\")\n",
        "embeddings_df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "wHQUy394K_5s",
        "outputId": "36a2d99d-8809-456f-b311-5d2959acdeae"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Unnamed: 0                       thread_id  \\\n",
              "0           0  2022-03-22 19:42:06.219769 UTC   \n",
              "1           1  2022-03-24 08:14:33.140029 UTC   \n",
              "2           2  2022-03-28 11:57:42.840049 UTC   \n",
              "3           3  2022-04-12 14:36:00.144498 UTC   \n",
              "4           4  2022-04-19 10:24:57.455849 UTC   \n",
              "\n",
              "                                           embedding  \n",
              "0  [0.0036350293084979057, -0.01264416053891182, ...  \n",
              "1  [-0.002360287122428417, -0.04199115186929703, ...  \n",
              "2  [0.017543835565447807, 0.0032007887493819, 0.0...  \n",
              "3  [-0.001173610333353281, -0.014446504414081573,...  \n",
              "4  [-0.0025763490702956915, -0.02925489842891693,...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-3f068e38-6306-41e9-b3ce-25f2384b4406\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>thread_id</th>\n",
              "      <th>embedding</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>2022-03-22 19:42:06.219769 UTC</td>\n",
              "      <td>[0.0036350293084979057, -0.01264416053891182, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>2022-03-24 08:14:33.140029 UTC</td>\n",
              "      <td>[-0.002360287122428417, -0.04199115186929703, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>2022-03-28 11:57:42.840049 UTC</td>\n",
              "      <td>[0.017543835565447807, 0.0032007887493819, 0.0...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>2022-04-12 14:36:00.144498 UTC</td>\n",
              "      <td>[-0.001173610333353281, -0.014446504414081573,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>2022-04-19 10:24:57.455849 UTC</td>\n",
              "      <td>[-0.0025763490702956915, -0.02925489842891693,...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3f068e38-6306-41e9-b3ce-25f2384b4406')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-3f068e38-6306-41e9-b3ce-25f2384b4406 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-3f068e38-6306-41e9-b3ce-25f2384b4406');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get your embeddings data together.\n",
        "import json\n",
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "\n",
        "# Create a temp index of the chats\n",
        "chats_index = {}\n",
        "for _, row in tqdm(chats_df.iterrows(), desc=\"Creating temporary chats index\"):\n",
        "  chats_index[row['thread_id']] = row['chat_text']\n",
        "\n",
        "# Link the chats and embeddings together\n",
        "embeddings = []\n",
        "VECTOR_SIZE = None\n",
        "for _, row in tqdm(embeddings_df.iterrows(), desc=\"Collecting chats and embeddings\"):\n",
        "  embedding = json.loads(row['embedding'])\n",
        "  embeddings.append({\"thread_id\": row['thread_id'], \"embedding\":  embedding})\n",
        "  if not VECTOR_SIZE:\n",
        "    VECTOR_SIZE = len(embedding)\n",
        "  else:\n",
        "    assert VECTOR_SIZE==len(embedding)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4wAmWK4dMg_8",
        "outputId": "efb9ea74-2efc-4b78-b90f-ef07c937bd62"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Creating temporary chats index: 9719it [00:00, 20207.57it/s]\n",
            "Collecting chats and embeddings: 9713it [00:08, 1152.50it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Create your vector database\n",
        "Using https://redis-py.readthedocs.io/en/stable/examples/search_vector_similarity_examples.html"
      ],
      "metadata": {
        "id": "E_MIq52NMbyT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "# Point to your self-hosted redis server OR try a free redis cloud server from https://redis.com/try-free/\n",
        "os.environ['REDIS_URL'] = \"YOUR_REDIS_KEY_HERE\""
      ],
      "metadata": {
        "id": "IKHwaN-MLICJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import redis\n",
        "from redis.commands.search.field import TagField, VectorField, TextField\n",
        "from redis.commands.search.indexDefinition import IndexDefinition, IndexType\n",
        "from redis.commands.search.query import Query\n",
        "\n",
        "r = redis.StrictRedis.from_url(os.environ['REDIS_URL'])\n",
        "r.ping()\n",
        "\n",
        "INDEX_NAME = \"vector_index\"                              # Vector Index Name\n",
        "DOC_PREFIX = \"DOC:\"                                      # RediSearch Key Prefix for the Index\n",
        "assert VECTOR_SIZE\n",
        "\n",
        "def create_index(vector_dimensions: int=VECTOR_SIZE):\n",
        "    try:\n",
        "        # check to see if index exists\n",
        "        r.ft(INDEX_NAME).info()\n",
        "        print(\"Index already exists!\")\n",
        "    except:\n",
        "        # schema - we have two fields in our object - thread_id, and embedding\n",
        "        schema = (\n",
        "            VectorField(\"vector\",                  # Vector Field Name\n",
        "                \"FLAT\", {                          # Vector Index Type: FLAT or HNSW\n",
        "                    \"TYPE\": \"FLOAT32\",             # FLOAT32 or FLOAT64\n",
        "                    \"DIM\": vector_dimensions,      # Number of Vector Dimensions\n",
        "                    \"DISTANCE_METRIC\": \"COSINE\",   # Vector Search Distance Metric\n",
        "                }\n",
        "            ),\n",
        "        )\n",
        "\n",
        "        # index Definition\n",
        "        definition = IndexDefinition(prefix=[DOC_PREFIX], index_type=IndexType.HASH)\n",
        "\n",
        "        # create Index\n",
        "        r.ft(INDEX_NAME).create_index(fields=schema, definition=definition)"
      ],
      "metadata": {
        "id": "dtAsNPAEL-fV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the empty index\n",
        "create_index(vector_dimensions=VECTOR_SIZE)"
      ],
      "metadata": {
        "id": "_4VCtBrfOXT_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# bulk insert data\n",
        "pipe = r.pipeline()\n",
        "for row in tqdm(embeddings):\n",
        "    # define key\n",
        "    key = f\"{DOC_PREFIX}{row['thread_id']}\"\n",
        "    # HSET\n",
        "    pipe.hset(key, mapping={\"vector\": np.array(row['embedding']).astype(np.float32).tobytes()})\n",
        "res = pipe.execute()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0MfzhP7KP7PT",
        "outputId": "beb0ca60-2a51-4aaf-c12b-e32e46827daf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9713/9713 [00:01<00:00, 5850.85it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def search_index(vector, vector_dimensions: int = VECTOR_SIZE):  \n",
        "  query = (\n",
        "    Query(\"*=>[KNN 2 @vector $vec as score]\")\n",
        "     .sort_by(\"score\")\n",
        "     .return_fields(\"id\", \"score\")\n",
        "     .paging(0, 3)\n",
        "     .dialect(2)\n",
        "  )\n",
        "\n",
        "  query_params = {\n",
        "      \"vec\": vector\n",
        "  }\n",
        "  return r.ft(INDEX_NAME).search(query, query_params).docs"
      ],
      "metadata": {
        "id": "pS_lC8k6SJTQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# test with an existing document, that that document is returned\n",
        "row = embeddings[2539]\n",
        "docs = search_index(np.array(row['embedding']).astype(np.float32).tobytes())\n",
        "assert f\"{DOC_PREFIX}{row['thread_id']}\"==docs[0].id, \"Document does not match\""
      ],
      "metadata": {
        "id": "jI_XJYqwY0pP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Example Q&A with OpenAI"
      ],
      "metadata": {
        "id": "nuiB3wZHbb2_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install openai"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GRTZ6vB1ZfB6",
        "outputId": "8dbcd4a5-ffcc-40f0-edb7-487e8f0e6e1f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: openai in /usr/local/lib/python3.10/dist-packages (0.27.7)\n",
            "Requirement already satisfied: requests>=2.20 in /usr/local/lib/python3.10/dist-packages (from openai) (2.27.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai) (4.65.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from openai) (3.8.4)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (3.4)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (23.1.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (6.0.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (4.0.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (1.3.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (1.3.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import openai\n",
        "openai.organization = \"YOUR_ORG_ID_IN_OPENAI\"\n",
        "openai.api_key = \"YOUR_OPENAI_API_KEY\"\n",
        "\n",
        "def get_embedding(text):  \n",
        "  # Use the same embedding generator as what was used on the data!!!\n",
        "  response = openai.Embedding.create(\n",
        "    model=\"text-embedding-ada-002\",\n",
        "    input=text\n",
        "  )\n",
        "  return response.data[0].embedding\n",
        "\n",
        "def summarize(chat_text):\n",
        "  # Summarize conversations since individually they are long and go over 8k limit\n",
        "  prompt = \"Summarize the following conversation on the MLOps.community slack channel. Do not use the usernames in the summary. ```\" + chat_text + \"```\"\n",
        "  completion = openai.ChatCompletion.create(\n",
        "    model=\"gpt-3.5-turbo\",\n",
        "    messages=[\n",
        "      {\"role\": \"user\", \"content\": prompt}\n",
        "    ]\n",
        "  )\n",
        "  return completion.choices[0].message.content\n",
        "  \n",
        "\n",
        "def extract_answer(chat_texts, question):  \n",
        "  # Combine the summaries into a prompt and use SotA GPT-4 to answer.\n",
        "  prompt = \"Use the following summaries of conversations on the MLOps.community slack channel backtics to generate an answer for the user question.\"\n",
        "  for i, chat_text in enumerate(chat_texts):\n",
        "    print(f\"Getting summary for conversation {i+1}\")\n",
        "    prompt += f\"\\nConversation {i+1} Summary:\\n```\\n{summarize(chat_text)}```\"\n",
        "\n",
        "  if not question.endswith(\"?\"):\n",
        "    question = question + \"?\"\n",
        "  prompt+= f\"\\nQuestion: {question}\"\n",
        "  print(f\"Getting answer for the question.\")\n",
        "  completion = openai.ChatCompletion.create(\n",
        "    model=\"gpt-4\",\n",
        "    messages=[\n",
        "      {\"role\": \"user\", \"content\": prompt}\n",
        "    ]\n",
        "  )\n",
        "  content = completion.choices[0].message.content\n",
        "  return content\n"
      ],
      "metadata": {
        "id": "Ij-IEfqlbevd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_answer(question):\n",
        "  # Get answer to the question by finding the three conversations that are nearest \n",
        "  # to the question and then using them to generate the answer.\n",
        "  print(f\"Searching documents nearest to the question.\")\n",
        "  search_vector = np.array(get_embedding(question)).astype(np.float32).tobytes()\n",
        "  docs = search_index(search_vector)\n",
        "  # Take the top three answers, and use ChatGPT to form the answer to give the user.\n",
        "  chat_texts = []\n",
        "  for doc in docs:\n",
        "    chat_text = chats_index[doc.id[len(DOC_PREFIX):]]\n",
        "    chat_texts.append(chat_text)\n",
        "  if len(chat_texts)>3:\n",
        "    chat_texts[:3]\n",
        "  return extract_answer(chat_texts, question)"
      ],
      "metadata": {
        "id": "4FTUR7aSbiR4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "question=\"What are some good ways to deploy models on Kubernetes?\"\n",
        "answer = get_answer(question)\n",
        "print(f\"\\n\\nQuestion: {question}\\nAnswer: {answer}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 231
        },
        "id": "bZDd3d5lcSSz",
        "outputId": "e333a17a-e5c1-4675-bf97-9fe1b1f51fc9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Searching documents nearest to the question.\n",
            "Getting summary for conversation 1\n",
            "Getting summary for conversation 2\n",
            "Getting answer for the question.\n",
            "\n",
            "\n",
            "Question: What are some good ways to deploy models on Kubernetes?\n",
            "Answer: Some good ways to deploy models on Kubernetes include using popular ML frameworks such as TensorFlow or PyTorch, along with their respective model serving tools like TensorFlow Serving or TorchServe. You can also try alternatives such as ONNXRuntime or Seldon. For custom preprocessing and post-processing, consider using tools like Algorithmia or Iguazio. Additionally, MLflow can be used for easy adoption by data scientists. When dealing with large models or facing memory limitations, it is recommended to separate the API/web service from the model inference service, allowing for independent scaling.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "question=\"How can I structure a good Data Science team?\"\n",
        "answer = get_answer(question)\n",
        "print(f\"\\n\\nQuestion: {question}\\nAnswer: {answer}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 481
        },
        "id": "Ub0bI4roeUHK",
        "outputId": "134df44e-5e10-486b-f56a-a63507aa3940"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Searching documents nearest to the question.\n",
            "Getting summary for conversation 1\n",
            "Getting summary for conversation 2\n",
            "Getting answer for the question.\n",
            "\n",
            "\n",
            "Question: How can I structure a good Data Science team?\n",
            "Answer: A good Data Science team structure can involve the following elements based on the conversations in the MLOps.community slack channel:\n",
            "\n",
            "1. Embed data science within product teams: This helps in giving them context to the business problems they are solving and fostering collaboration between data scientists and other team members.\n",
            "\n",
            "2. Have a matrix structure with a centralized ML team: This ensures that there is a dedicated group of professionals who can guide data science efforts, share best practices, and streamline operations.\n",
            "\n",
            "3. Educate stakeholders and other teams about data science efforts, unpredictable timelines, model accuracy, and business value. This will help in setting realistic expectations and cooperation from other teams.\n",
            "\n",
            "4. Depending on the organization's needs, you may want to delegate data science work to infrastructure software engineers or ML engineers, as mentioned in Google's example.\n",
            "\n",
            "5. Consider if your team's work is focused on building pipelines, or if it's more of an on-demand expertise situation (e.g., working on small MVPs). Adjust team structure accordingly, and ensure roles and responsibilities are clearly defined.\n",
            "\n",
            "It's important to tailor your Data Science team structure to the specific needs and objectives of your organization while maintaining a focus on collaboration, education, and adaptability.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "question=\"What is the best way to train models for tabular data?\"\n",
        "answer = get_answer(question)\n",
        "print(f\"\\n\\nQuestion: {question}\\nAnswer: {answer}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 231
        },
        "id": "Hx4hElL0kzlV",
        "outputId": "d06244b1-79cc-4ae3-b36e-79a6db1bcc99"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Searching documents nearest to the question.\n",
            "Getting summary for conversation 1\n",
            "Getting summary for conversation 2\n",
            "Getting answer for the question.\n",
            "\n",
            "\n",
            "Question: What is the best way to train models for tabular data?\n",
            "Answer: There isn't a definitive \"best way\" to train models for tabular data, as it often depends on the problem you are working on and the dataset size. However, from the conversations, it seems that decision trees, especially boosted trees, tend to perform better than neural networks in many scenarios for working with tabular data. Additionally, using smart sampling and limited hyperparameter tuning can help in achieving accurate models without requiring the extra time and resources needed for neural networks. For time-series problems, non-neural network methods like the Facebook-developed library prophet can also work well.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "r-tnVPN3laIl"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}